{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cellular-lawyer",
   "metadata": {
    "id": "naked-volleyball"
   },
   "outputs": [],
   "source": [
    "# Run this cell if you are using Google Colab\n",
    "%%capture\n",
    "! pip install arviz==0.11.00\n",
    "! pip install pymc3==3.11.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "removable-proof",
   "metadata": {
    "id": "designed-insulin"
   },
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import seaborn as sns\n",
    "from pymc3 import math\n",
    "from scipy import stats\n",
    "\n",
    "sns.set_context('talk')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-theory",
   "metadata": {
    "id": "GWMGsEDSzosM"
   },
   "source": [
    "# Portfolio 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "micro-queue",
   "metadata": {
    "id": "fM0gAqRdKTcA"
   },
   "source": [
    "In the following exercises, we are going to analyse response time data  from a recent paper [(Legrand et al., 2021)](https://www.biorxiv.org/content/10.1101/2021.02.18.431871v1) using PyMC3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "expensive-hepatitis",
   "metadata": {
    "id": "QAxgnhh98LEo"
   },
   "outputs": [],
   "source": [
    "# Load data frame\r\n",
    "psychophysics_df = pd.read_csv('https://github.com/embodied-computation-group/CardioceptionPaper/raw/main/data/Del2_merged.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assisted-trash",
   "metadata": {
    "id": "GvOJcp0yf4Cj"
   },
   "source": [
    "## Exercise 1 - Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-investor",
   "metadata": {
    "id": "-z2rrtNp9MPh"
   },
   "source": [
    "This data frame contains behavioral results from a lot of participants, doing a lot of different tasks. The data of interest for us are stored in the `ConfidenceRT` column. This is the time the participant takes to rate a confidence rating scale. Before we go to the analysis part, we should filter this data frame a bit.\r\n",
    "\r\n",
    "* Here we only want to analyze the modality labeled as `Intero`, and drop the other one. \r\n",
    "* We only want to keep the `Subject` and the `ConfidenceRT` columns. \r\n",
    "* Sometimes, no responses were made by the participant, so the column potentially contains NaN values that should be removed. \r\n",
    "* Because we are just testing new models here, we only want to analyze a sub-sample of the data to save time and memory, so we are going to analyze subjects whose ID ends with a `7` and drop the rest of the participants.\r\n",
    "\r\n",
    "You should end up with a data frame containing 2 columns, 1158 rows, and the response time data from 20 participants in total. If you have difficulties doing this filtering process, you can just skip this question and use the entire `ConfidenceRT` column for the next questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-cathedral",
   "metadata": {
    "id": "U0T9eifxMiDP"
   },
   "source": [
    "## Exercise 2 - Gaussian model\r\n",
    "There are many ways to describe response time distribution. The most intuitive and simple model would be to use a normal distribution and use the mean and precision of this distribution as parameters of interest for each subject.\r\n",
    "\r\n",
    "We know from the experimental design that the response time cannot be less than 0 seconds or more than 5 seconds. Our first guess will be to use a normal distribution with a mean $\\mu$ and a standard deviation $\\sigma$. The mean might come from another normal distribution centered at 2.5. We don't want it to be too informative so the standard deviation will be set at 10. The standard deviation might come from a HalfCauchy distribution with a beta parameter set to `2`.\r\n",
    "\r\n",
    "* Use PyMC3 to fit this model to the responses from the first participant only (`sub_0027`) and create one plot using Arviz to synthesize your results.\r\n",
    "* Why did you choose this plot?\r\n",
    "* Describe what is represented in your plot\r\n",
    "* What information should we check if we want to make sure that the MCMC chain from this model can be trusted?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premium-thompson",
   "metadata": {
    "id": "ImUV1JlVnOIe"
   },
   "source": [
    "## Exercise 3 - Precision\r\n",
    "\r\n",
    "You want to compare your results with another model from the literature that describes the normal distribution using precision ($\\lambda$), and not the standard deviation ($\\sigma$). We know that: $$\\sigma = \\frac{1}{\\sqrt{\\lambda}}$$\r\n",
    "\r\n",
    "* Use `az. summary` to extract the $\\sigma$ value from the previous model, and convert it into a precision ($\\lambda$) value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "established-reaction",
   "metadata": {
    "id": "FSVOINMusDyU"
   },
   "source": [
    "## Exercise 4 - posterior predictive checks\r\n",
    "\r\n",
    "It turns out that this gaussian model is a terrible one for many reasons. We can explore this a bit more by checking the posterior predictive.\r\n",
    "\r\n",
    "* Extract the posterior predictive for this model using the default parameters from PyMC3.\r\n",
    "* Plot posterior predictive checks using built-in Arviz function.\r\n",
    "* What does this plot tells us? \r\n",
    "* What are the 2 main disadvantages here for response time data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-music",
   "metadata": {
    "id": "JwRq3_Oi8hZt"
   },
   "source": [
    "## Exercise 5 - A better model\r\n",
    "\r\n",
    "The normal distribution is indeed a poor fit for response time data. Other sources suggest that the Gamma distribution or the shifted Wald distribution might do a better job (see [this paper](https://www.frontiersin.org/articles/10.3389/fpsyg.2019.00102/full)). You can find all these distributions already implemented in PyMC3.\r\n",
    "\r\n",
    "Using the same data from subject 27, fit, plot, and summarize the following models separately.\r\n",
    "\r\n",
    "* The gamma model\r\n",
    "\r\n",
    "$$ y \\sim \\mathcal{Gamma}(mu=\\alpha, sigma=\\beta)$$\r\n",
    "$$ \\alpha \\sim \\mathcal{Uniform}(0, 5)$$\r\n",
    "$$ \\beta \\sim  \\mathcal{Uniform}(0, 5)$$\r\n",
    "\r\n",
    "* The Wald model\r\n",
    "\r\n",
    "$$ y \\sim \\mathcal{Wald}(\\mu, \\lambda)$$\r\n",
    "$$ \\mu \\sim \\mathcal{Uniform}(0, 5)$$\r\n",
    "$$ \\lambda \\sim  \\mathcal{Uniform}(0, 20)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "academic-example",
   "metadata": {
    "id": "sSHLNUxeHeTL"
   },
   "source": [
    "## Exercise 6 - Plotting model results\r\n",
    "\r\n",
    "Using the parameters estimates from the previous models, Matplotlib, Seaborn, and the `scipy.stats`module, try to reproduce the following plot\n",
    "![title](https://github.com/LegrandNico/CognitiveModeling/raw/master/notebooks/data/wald_gamma.png)\n",
    ":\r\n",
    "\r\n",
    "**Hint**: You can use the gamma function from Scipy to estimate the probability density function, but you will have to create your own Wald function to make it work with the parameters `mu` and `lam` estimated by PyMC3 (see the formula [here](https://en.wikipedia.org/wiki/Inverse_Gaussian_distribution))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sudden-pleasure",
   "metadata": {
    "id": "kd3oBNR0Am6Q"
   },
   "source": [
    "## Exercise 6 - Model comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-genetics",
   "metadata": {},
   "source": [
    "Compare the previous models (normal distribution, Gamma, Wald). Which one should we choose? What are the metrics/indexes you use to make your decision?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binding-beads",
   "metadata": {
    "id": "YnN8WpRF5vW6"
   },
   "source": [
    "## Exercise 7 - Decision\r\n",
    "\r\n",
    "Imagine the following (completely fictitious) situation: Previous researches have shown that the $\\mu$ parameter estimated from the Wald distribution is associated with the anxiety level of the participant. The lower this parameter is, the faster the participant is at confidence rating, and the greater the anxiety level is. If $\\mu$ is below 1.2, the anxiety level is considered clinically relevant and the participant should be oriented to a specialist.\r\n",
    "\r\n",
    "You want to make a decision concerning subject 27, and you want to make it probabilistically (i.e. you want to take the decision, but also estimate how sure you are about this decision).\r\n",
    "\r\n",
    "* Given your estimation of $\\mu$ from the previous model, do you consider this score to be clinically relevant here?\r\n",
    "* What is the probability that $\\mu$ is acless thany below 1.2 for this participant?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-gathering",
   "metadata": {
    "id": "gCROcPnkvj6a"
   },
   "source": [
    "## Exercise 8 - Hierarchical model\r\n",
    "\r\n",
    "Using the entire dataset this time (20 subjects), we are going to fit a hierarchical Wald model. Instead of fixing the prior of the parameters of the Wald function, we want to sample them from hyperpriors (i.e each participant will have its own $\\mu$ and $\\lambda$ parameters coming from a unique normal distributionm and we want to estimate the mean and standard deviation of these distributions). The hierarchical model for $i = 20$ participants is defined by:\r\n",
    "\r\n",
    "$$ y_{i} \\sim \\mathcal{Wald}(\\mu_{i}, \\lambda_{i})$$\r\n",
    "$$ \\mu_{i} \\sim \\mathcal{N}(\\mu_{\\mu}, \\sigma_{\\mu})$$\r\n",
    "$$ \\lambda_{i} \\sim  \\mathcal{N}(\\mu_{\\lambda}, \\sigma_{\\lambda})$$\r\n",
    "\r\n",
    "$$\\mu_{\\mu} \\sim \\mathcal{Uniform}(0, 100)$$\r\n",
    "$$\\mu_{\\lambda} \\sim \\mathcal{Uniform}(0, 100)$$\r\n",
    "\r\n",
    "$$\\sigma_{\\mu} \\sim \\mathcal{HalfCauchy}(10)$$\r\n",
    "$$\\sigma_{\\lambda} \\sim \\mathcal{HalfCauchy}(10)$$\r\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "portfolio1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
